{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from collections import Counter\nimport cv2\nimport os\nimport glob\nimport skimage\nimport numpy as np\nimport pandas as pd\nimport seaborn as sn\nimport preprocessing\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom os import listdir\nimport matplotlib.pyplot as plt\nfrom skimage.transform import resize\nfrom collections import Counter\n\nsn.set()\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC # SVC\nfrom sklearn import metrics\nfrom sklearn.utils import shuffle\nfrom xgboost import XGBClassifier # XGBClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score,f1_score,recall_score,cohen_kappa_score,precision_score\nfrom sklearn.utils import compute_class_weight\nfrom sklearn.preprocessing import MinMaxScaler,LabelBinarizer\nfrom sklearn.ensemble import AdaBoostClassifier # AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier # KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier # RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow \nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications.vgg16 import VGG16 # VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19 # VGG19\nfrom tensorflow.keras.applications.resnet50 import ResNet50 # ResNet50\nfrom tensorflow.keras.applications import ResNet101\nfrom tensorflow.keras.applications.xception import Xception # Xception\nfrom tensorflow.keras.applications.mobilenet import MobileNet # MobileNet\nfrom tensorflow.keras.applications.nasnet import NASNetMobile # NASNetMobile\nfrom tensorflow.keras.applications.densenet import DenseNet169 # DenseNet169\nfrom tensorflow.keras.applications.densenet import DenseNet121 # DenseNet121\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 # MobileNetV2\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3 # InceptionV3\nfrom tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_angles = 360\nurl ='/kaggle/input/mias-mammography/all-mias/'","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_dictionary(path,data):\n    print('saving catalog...')\n    #open('u.item', encoding=\"utf-8\")\n    import json\n    with open(path,'w') as outfile:\n        json.dump(str(data), fp=outfile)\n      # save to file:\n    print(' catalog saved')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image():\n    print(\"Reading images\")\n    import cv2\n    info = {}\n    for i in range(322):\n        if i<9:\n            image_name='mdb00'+str(i+1)\n        elif i<99:\n            image_name='mdb0'+str(i+1)\n        else:\n            image_name = 'mdb' + str(i+1)\n        # print(image_name)\n        image_address= url+image_name+'.pgm'\n        #print(image_address)\n        #print(image_address)\n        img = cv2.imread(image_address,1)\n        # print(i)\n        img = cv2.resize(img, (224,224))   #resize image\n        rows, cols,color = img.shape\n        info[image_name]={}\n        for angle in range(0,no_angles,8):\n            M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)    #Rotate 0 degree\n            img_rotated = cv2.warpAffine(img, M, (cols, rows))\n            info[image_name][angle]=img_rotated\n    return (info)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_lable():\n    print(\"Reading labels\")\n    filename = url+'Info.txt'\n    text_all = open(filename).read()\n    #print(text_all)\n    lines=text_all.split('\\n')\n    info={}\n    for line in lines:\n        words=line.split(' ')       \n        if len(words)>3:\n            if (words[3] == 'B'):\n                info[words[0]] = {}\n                for angle in range(0,no_angles,8):\n                    info[words[0]][angle] = 0\n            if (words[3] == 'M'):\n                info[words[0]] = {}\n                for  angle in range(0,no_angles,8):\n                    info[words[0]][angle] = 1\n    return (info)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nimport numpy as np\nlable_info=read_lable()\nimage_info=read_image()\n#print(image_info[1][0])\nids=lable_info.keys()   #ids = acceptable labeled ids\n#print(type(ids))\ndel lable_info['Truth-Data:']\n#print(lable_info)\n#print(ids)\nX=[]\nY=[]\nfor id in ids:\n    for angle in range(0,no_angles,8):\n        X.append(image_info[id][angle])\n        Y.append(lable_info[id][angle])\nX=np.array(X)\nY=np.array(Y)\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=2021,shuffle=True)\n# cancer_prediction_cnn(x_train, y_train, x_test, y_test)","execution_count":6,"outputs":[{"output_type":"stream","text":"Reading labels\nReading images\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Conv2D, MaxPool2D, Flatten\nfrom keras import optimizers\nfrom keras import losses\nfrom sklearn import metrics\n\nrows, cols,color = x_train[0].shape\nprint(x_train[0].shape)\n\nbase_model = MobileNet(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Dropout(0.2)(x)\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(128,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx = Dense(128,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\nx = Activation('relu')(x)\nx =  Dropout(0.5)(x)\npredictions = Dense(16, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(x_train)\ntest_features=model_feat.predict(x_test)","execution_count":7,"outputs":[{"output_type":"stream","text":"(224, 224, 3)\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n17227776/17225924 [==============================] - 0s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_acc, x_val_acc, y_train_acc, y_val_acc = train_test_split(train_features,y_train,\n                                                  test_size = 0.15,\n                                                  shuffle = True,\n                                                  random_state = 2021)\nX_test,y_test=test_features,y_test","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('length X_train:', len(x_train_acc))\nprint('length y_train:', len(y_train_acc))\n\nprint('length X_val:',  len(x_val_acc))\nprint('length y_val:', len(y_val_acc))\n\nprint('length X_test:',  len(X_test))\nprint('length y_test:', len(y_test))","execution_count":9,"outputs":[{"output_type":"stream","text":"length X_train: 3738\nlength y_train: 3738\nlength X_val: 660\nlength y_val: 660\nlength X_test: 777\nlength y_test: 777\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_acc[0].shape","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"(16,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n        ]\n\nzipped_clf = zip(names,classifiers)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    \n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    train_confusion_matrix = confusion_matrix(y_train,y_pred_train)\n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n    val_confusion_matrix = confusion_matrix(y_val,y_pred_val)\n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2) \n    test_confusion_matrix = confusion_matrix(y_test,y_pred_test)\n    \n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"accuracy : {}%\".format(train_accuracy))\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"accuracy : {}%\".format(val_accuracy))\n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"accuracy : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Cohen Kappa Score : {} \".format(test_kappa))\n    print(\"Recall : {}\".format(test_recall))\n    print(\"Precision : {}\".format(test_precision))\n    print(\"Confusion Matrix : {}\".format(test_confusion_matrix))\n\n    print(\"-\"*80)\n    print()","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('classifier', c)])\n        print(\"Fitting {} on features \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_comparator(x_train_acc,y_train_acc,x_val_acc,y_val_acc,X_test,y_test,classifier=zipped_clf)","execution_count":14,"outputs":[{"output_type":"stream","text":"Fitting K Nearest Neighbour Classifier on features \n\n------------------------ Train Set Metrics------------------------\n\naccuracy : 70.19999999999999%\n------------------------ Validation Set Metrics------------------------\n\naccuracy : 52.88%\n------------------------ Test Set Metrics------------------------\n\naccuracy : 49.81%\nF1_score : 0.49\nCohen Kappa Score : -0.02 \nRecall : 0.5\nPrecision : 0.49\nConfusion Matrix : [[248 170]\n [220 139]]\n--------------------------------------------------------------------------------\n\nFitting SVM on features \n\n------------------------ Train Set Metrics------------------------\n\naccuracy : 57.379999999999995%\n------------------------ Validation Set Metrics------------------------\n\naccuracy : 54.39000000000001%\n------------------------ Test Set Metrics------------------------\n\naccuracy : 53.28000000000001%\nF1_score : 0.42\nCohen Kappa Score : 0.0 \nRecall : 0.53\nPrecision : 0.5\nConfusion Matrix : [[388  30]\n [333  26]]\n--------------------------------------------------------------------------------\n\nFitting Random Forest Classifier on features \n\n------------------------ Train Set Metrics------------------------\n\naccuracy : 100.0%\n------------------------ Validation Set Metrics------------------------\n\naccuracy : 55.61000000000001%\n------------------------ Test Set Metrics------------------------\n\naccuracy : 52.900000000000006%\nF1_score : 0.51\nCohen Kappa Score : 0.03 \nRecall : 0.53\nPrecision : 0.52\nConfusion Matrix : [[299 119]\n [247 112]]\n--------------------------------------------------------------------------------\n\nFitting AdaBoost Classifier on features \n\n------------------------ Train Set Metrics------------------------\n\naccuracy : 61.82%\n------------------------ Validation Set Metrics------------------------\n\naccuracy : 53.94%\n------------------------ Test Set Metrics------------------------\n\naccuracy : 51.349999999999994%\nF1_score : 0.49\nCohen Kappa Score : -0.01 \nRecall : 0.51\nPrecision : 0.5\nConfusion Matrix : [[298 120]\n [258 101]]\n--------------------------------------------------------------------------------\n\nFitting XGB Classifier on features \n\n------------------------ Train Set Metrics------------------------\n\naccuracy : 99.76%\n------------------------ Validation Set Metrics------------------------\n\naccuracy : 53.94%\n------------------------ Test Set Metrics------------------------\n\naccuracy : 54.56999999999999%\nF1_score : 0.54\nCohen Kappa Score : 0.08 \nRecall : 0.55\nPrecision : 0.54\nConfusion Matrix : [[267 151]\n [202 157]]\n--------------------------------------------------------------------------------\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ann=Sequential()\nann.add(Dense(16,activation='relu',input_shape=x_train_acc[0].shape))\nann.add(Dense(32,activation='relu'))\nann.add(Dense(64,activation='relu'))\nann.add(Dense(64,activation='relu'))\nann.add(Dense(32,activation='relu'))\nann.add(Dense(16,activation='relu'))\nann.add(Dense(1,activation='sigmoid'))\n\nann.summary()\n\nann.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory = ann.fit(x_train_acc, y_train_acc,validation_data=(x_val_acc,y_val_acc), epochs=20)\n\nloss_value , accuracy = ann.evaluate(x_train_acc, y_train_acc)\nprint('Train_accuracy = ' + str(accuracy))\nloss_value , accuracy = ann.evaluate(x_val_acc, y_val_acc)\nprint('Validation_accuracy = ' + str(accuracy))\nloss_value , accuracy = ann.evaluate(X_test, y_test)\nprint('test_accuracy = ' + str(accuracy))","execution_count":15,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_4 (Dense)              (None, 32)                544       \n_________________________________________________________________\ndense_5 (Dense)              (None, 64)                2112      \n_________________________________________________________________\ndense_6 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_7 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_8 (Dense)              (None, 16)                528       \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 9,713\nTrainable params: 9,713\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/20\n117/117 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.5479 - val_loss: 0.6880 - val_accuracy: 0.5545\nEpoch 2/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5487 - val_loss: 0.6876 - val_accuracy: 0.5545\nEpoch 3/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5487 - val_loss: 0.6878 - val_accuracy: 0.5545\nEpoch 4/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5487 - val_loss: 0.6879 - val_accuracy: 0.5545\nEpoch 5/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5487 - val_loss: 0.6883 - val_accuracy: 0.5545\nEpoch 6/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5487 - val_loss: 0.6880 - val_accuracy: 0.5545\nEpoch 7/20\n117/117 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5487 - val_loss: 0.6886 - val_accuracy: 0.5545\nEpoch 8/20\n117/117 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5487 - val_loss: 0.6882 - val_accuracy: 0.5545\nEpoch 9/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5487 - val_loss: 0.6913 - val_accuracy: 0.5591\nEpoch 10/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.5613 - val_loss: 0.6899 - val_accuracy: 0.5545\nEpoch 11/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5556 - val_loss: 0.6910 - val_accuracy: 0.5470\nEpoch 12/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.5634 - val_loss: 0.6905 - val_accuracy: 0.5576\nEpoch 13/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.5655 - val_loss: 0.6909 - val_accuracy: 0.5424\nEpoch 14/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.5621 - val_loss: 0.7084 - val_accuracy: 0.4985\nEpoch 15/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.5647 - val_loss: 0.6891 - val_accuracy: 0.5530\nEpoch 16/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.5658 - val_loss: 0.6967 - val_accuracy: 0.5152\nEpoch 17/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5645 - val_loss: 0.6943 - val_accuracy: 0.5288\nEpoch 18/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.5704 - val_loss: 0.6912 - val_accuracy: 0.5348\nEpoch 19/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.5693 - val_loss: 0.6965 - val_accuracy: 0.5455\nEpoch 20/20\n117/117 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.5701 - val_loss: 0.6880 - val_accuracy: 0.5470\n117/117 [==============================] - 0s 2ms/step - loss: 0.6767 - accuracy: 0.5776\nTrain_accuracy = 0.5775815844535828\n21/21 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.5470\nValidation_accuracy = 0.5469697117805481\n25/25 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.5367\ntest_accuracy = 0.5366795659065247\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=ann.predict_classes(X_test)\ntarget=[\"B\",\"M\"]\nprint('Accuracy:', np.round(metrics.accuracy_score(y_test, y_pred),4))\nprint('Precision:', np.round(metrics.precision_score(y_test, y_pred, average='weighted'),4))\nprint('Recall:', np.round(metrics.recall_score(y_test,y_pred, average='weighted'),4))\nprint('F1 Score:', np.round(metrics.f1_score(y_test, y_pred, average='weighted'),4))\nprint('Cohen Kappa Score:', np.round(metrics.cohen_kappa_score(y_test, y_pred),4))\nprint('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred,target_names=target))","execution_count":16,"outputs":[{"output_type":"stream","text":"Accuracy: 0.5367\nPrecision: 0.52\nRecall: 0.5367\nF1 Score: 0.4523\nCohen Kappa Score: 0.0153\n\t\tClassification Report:\n               precision    recall  f1-score   support\n\n           B       0.54      0.89      0.68       418\n           M       0.49      0.12      0.19       359\n\n    accuracy                           0.54       777\n   macro avg       0.52      0.51      0.43       777\nweighted avg       0.52      0.54      0.45       777\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}